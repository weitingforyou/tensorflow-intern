{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ref: https://github.com/pkmital/tensorflow_tutorials/blob/master/python/09_convolutional_autoencoder.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def autoencoder(input_shape=[None, 784],\n",
    "                n_filters=[1, 10, 10, 10],\n",
    "                filter_sizes=[3, 3, 3, 3],\n",
    "                corruption=False):\n",
    "    \"\"\"Build a deep denoising autoencoder w/ tied weights.\n",
    "    Parameters\n",
    "    ----------\n",
    "    input_shape : list, optional\n",
    "        Description\n",
    "    n_filters : list, optional\n",
    "        Description\n",
    "    filter_sizes : list, optional\n",
    "        Description\n",
    "    Returns\n",
    "    -------\n",
    "    x : Tensor\n",
    "        Input placeholder to the network\n",
    "    z : Tensor\n",
    "        Inner-most latent representation\n",
    "    y : Tensor\n",
    "        Output reconstruction of the input\n",
    "    cost : Tensor\n",
    "        Overall cost to use for training\n",
    "    Raises\n",
    "    ------\n",
    "    ValueError\n",
    "        Description\n",
    "    \"\"\"\n",
    "    # %%\n",
    "    # input to the network\n",
    "    x = tf.placeholder(\n",
    "        tf.float32, input_shape, name='x')\n",
    "\n",
    "\n",
    "    # %%\n",
    "    # ensure 2-d is converted to square tensor.\n",
    "    if len(x.get_shape()) == 2:\n",
    "        x_dim = np.sqrt(x.get_shape().as_list()[1])\n",
    "        if x_dim != int(x_dim):\n",
    "            raise ValueError('Unsupported input dimensions')\n",
    "        x_dim = int(x_dim)\n",
    "        x_tensor = tf.reshape(\n",
    "            x, [-1, x_dim, x_dim, n_filters[0]])\n",
    "    elif len(x.get_shape()) == 4:\n",
    "        x_tensor = x\n",
    "    else:\n",
    "        raise ValueError('Unsupported input dimensions')\n",
    "    current_input = x_tensor\n",
    "\n",
    "    # %%\n",
    "    # Optionally apply denoising autoencoder\n",
    "    if corruption:\n",
    "        current_input = corrupt(current_input)\n",
    "\n",
    "    # %%\n",
    "    # Build the encoder\n",
    "    encoder = []\n",
    "    shapes = []\n",
    "    for layer_i, n_output in enumerate(n_filters[1:]):\n",
    "        n_input = current_input.get_shape().as_list()[3]\n",
    "        shapes.append(current_input.get_shape().as_list())\n",
    "        W = tf.Variable(\n",
    "            tf.random_uniform([\n",
    "                filter_sizes[layer_i],\n",
    "                filter_sizes[layer_i],\n",
    "                n_input, n_output],\n",
    "                -1.0 / math.sqrt(n_input),\n",
    "                1.0 / math.sqrt(n_input)))\n",
    "        b = tf.Variable(tf.zeros([n_output]))\n",
    "        encoder.append(W)\n",
    "        output = tf.nn.relu(\n",
    "            tf.add(tf.nn.conv2d(\n",
    "                current_input, W, strides=[1, 2, 2, 1], padding='SAME'), b))\n",
    "        current_input = output\n",
    "\n",
    "    # %%\n",
    "    # store the latent representation\n",
    "    z = current_input\n",
    "    encoder.reverse()\n",
    "    shapes.reverse()\n",
    "\n",
    "    # %%\n",
    "    # Build the decoder using the same weights\n",
    "    for layer_i, shape in enumerate(shapes):\n",
    "        W = encoder[layer_i]\n",
    "        b = tf.Variable(tf.zeros([W.get_shape().as_list()[2]]))\n",
    "        output = tf.nn.relu(tf.add(\n",
    "            tf.nn.conv2d_transpose(\n",
    "                current_input, W,\n",
    "                tf.pack([tf.shape(x)[0], shape[1], shape[2], shape[3]]),\n",
    "                strides=[1, 2, 2, 1], padding='SAME'), b))\n",
    "        current_input = output\n",
    "\n",
    "    # %%\n",
    "    # now have the reconstruction through the network\n",
    "    y = current_input\n",
    "    # cost function measures pixel-wise difference\n",
    "    cost = tf.reduce_sum(tf.square(y - x_tensor))\n",
    "\n",
    "    # %%\n",
    "    return {'x': x, 'z': z, 'y': y, 'cost': cost}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_mnist():\n",
    "    \"\"\"Test the convolutional autoencder using MNIST.\"\"\"\n",
    "    # %%\n",
    "    import tensorflow as tf\n",
    "    import tensorflow.examples.tutorials.mnist.input_data as input_data\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # %%\n",
    "    # load MNIST as before\n",
    "    mnist = input_data.read_data_sets('MNIST_data', one_hot=True)\n",
    "    mean_img = np.mean(mnist.train.images, axis=0)\n",
    "    ae = autoencoder()\n",
    "\n",
    "    # %%\n",
    "    learning_rate = 0.01\n",
    "    optimizer = tf.train.AdamOptimizer(learning_rate).minimize(ae['cost'])\n",
    "\n",
    "    # %%\n",
    "    # We create a session to use the graph\n",
    "    sess = tf.Session()\n",
    "    sess.run(tf.initialize_all_variables())\n",
    "\n",
    "    # %%\n",
    "    # Fit all training data\n",
    "    batch_size = 100\n",
    "    n_epochs = 100\n",
    "    for epoch_i in range(n_epochs):\n",
    "        for batch_i in range(mnist.train.num_examples // batch_size):\n",
    "            batch_xs, _ = mnist.train.next_batch(batch_size)\n",
    "            train = np.array([img - mean_img for img in batch_xs])\n",
    "            sess.run(optimizer, feed_dict={ae['x']: train})\n",
    "        print(epoch_i, sess.run(ae['cost'], feed_dict={ae['x']: train}))\n",
    "\n",
    "    # %%\n",
    "    # Plot example reconstructions\n",
    "    n_examples = 10\n",
    "    test_xs, _ = mnist.test.next_batch(n_examples)\n",
    "    test_xs_norm = np.array([img - mean_img for img in test_xs])\n",
    "    recon = sess.run(ae['y'], feed_dict={ae['x']: test_xs_norm})\n",
    "    print(recon.shape)\n",
    "    fig, axs = plt.subplots(2, n_examples, figsize=(10, 2))\n",
    "    for example_i in range(n_examples):\n",
    "        axs[0][example_i].imshow(\n",
    "            np.reshape(test_xs[example_i, :], (28, 28)))\n",
    "        axs[1][example_i].imshow(\n",
    "            np.reshape(\n",
    "                np.reshape(recon[example_i, ...], (784,)) + mean_img,\n",
    "                (28, 28)))\n",
    "    fig.show()\n",
    "    plt.draw()\n",
    "    plt.waitforbuttonpress()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "(0, 3705.293)\n",
      "(1, 2846.8105)\n",
      "(2, 2596.7112)\n",
      "(3, 2563.5898)\n",
      "(4, 2543.3713)\n",
      "(5, 2533.8511)\n",
      "(6, 2531.9167)\n",
      "(7, 2442.1938)\n",
      "(8, 2445.4055)\n",
      "(9, 2466.0112)\n",
      "(10, 2449.1045)\n",
      "(11, 2405.8174)\n",
      "(12, 2450.3596)\n",
      "(13, 2431.8562)\n",
      "(14, 2200.0132)\n",
      "(15, 2033.3085)\n",
      "(16, 2062.1934)\n",
      "(17, 2057.9622)\n",
      "(18, 1980.0103)\n",
      "(19, 1922.8379)\n",
      "(20, 2009.2473)\n",
      "(21, 1958.6932)\n",
      "(22, 2040.3059)\n",
      "(23, 1936.8992)\n",
      "(24, 1951.3107)\n",
      "(25, 1966.7255)\n",
      "(26, 1883.7319)\n",
      "(27, 1940.5466)\n",
      "(28, 1885.5221)\n",
      "(29, 1952.0466)\n",
      "(30, 2038.2723)\n",
      "(31, 1876.2955)\n",
      "(32, 1959.6556)\n",
      "(33, 1894.6228)\n",
      "(34, 1991.7112)\n",
      "(35, 1982.437)\n",
      "(36, 2002.178)\n",
      "(37, 1963.7827)\n",
      "(38, 1924.3682)\n",
      "(39, 1973.3567)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    test_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

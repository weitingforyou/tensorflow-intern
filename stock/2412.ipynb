{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "from yahoo_finance import Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_len = 9\n",
    "H = 256 # number of hidden layer neurons\n",
    "D = 9 # input dimensionality\n",
    "C = 2 # ouput classes \n",
    "n_input = 3 # MNIST data input (img shape: 2*2)\n",
    "n_steps = 3 # timesteps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "750\n"
     ]
    }
   ],
   "source": [
    "# get stock from yahoo-finance\n",
    "stock = Share('2412.TW')\n",
    "today = datetime.date.today()\n",
    "stock_data = stock.get_historical('2014-01-01', str(today))\n",
    "stock_data.reverse()\n",
    "print len(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data without zero volumn 698\n"
     ]
    }
   ],
   "source": [
    "# delete the zero-volumn data\n",
    "i = 0\n",
    "while( i < len(stock_data)):\n",
    "    if (int(stock_data[i].get('Volume')) <= 0):\n",
    "        stock_data.remove(stock_data[i])\n",
    "        i = -1\n",
    "    i += 1\n",
    "print 'data without zero volumn', len(stock_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# training and testing data\n",
    "data_X = np.zeros((len(stock_data)-day_len,day_len), dtype=np.float)\n",
    "data_Y = np.zeros((len(stock_data)-day_len,2), dtype = np.float)\n",
    "data_tag = []\n",
    "\n",
    "for i in xrange(0, len(data_X)):\n",
    "    for j in xrange(0, day_len):\n",
    "        data_X[i,j] = float(stock_data[i+j].get('Close')) - float(stock_data[i].get('Close'))\n",
    "        tmp = float(stock_data[i+day_len].get('Close')) - float(stock_data[i].get('Close'))\n",
    "    if tmp < 0 :\n",
    "        data_Y[i,0] = tmp\n",
    "        data_tag.append('fall')\n",
    "    else :\n",
    "        data_Y[i,1] = tmp\n",
    "        data_tag.append('rise')\n",
    "    \n",
    "len_train = int(len(data_X) * 0.8)\n",
    "len_test = len(data_X) - len_train\n",
    "\n",
    "train_X = data_X[0:len_train]\n",
    "train_Y = data_Y[0:len_train]\n",
    "test_X = data_X[len_train::]\n",
    "test_Y = data_Y[len_train::]\n",
    "train_tag = data_tag[0:len_train]\n",
    "test_tag = data_tag[len_train::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0. ,   2. ],\n",
       "        [  0. ,   0. ],\n",
       "        [  0. ,   0.5],\n",
       "        [ -1.5,   0. ],\n",
       "        [ -2. ,   0. ],\n",
       "        [  0. ,   1. ],\n",
       "        [  0. ,   1.5],\n",
       "        [ -0.5,   0. ],\n",
       "        [ -0.5,   0. ],\n",
       "        [ -1. ,   0. ],\n",
       "        [  0. ,   1. ],\n",
       "        [  0. ,   0.5],\n",
       "        [  0. ,   2.5],\n",
       "        [  0. ,   3. ],\n",
       "        [  0. ,   0. ],\n",
       "        [  0. ,   0. ],\n",
       "        [  0. ,   1.5],\n",
       "        [ -0.5,   0. ],\n",
       "        [ -0.5,   0. ],\n",
       "        [ -1. ,   0. ],\n",
       "        [  0. ,   0. ],\n",
       "        [ -1. ,   0. ],\n",
       "        [ -2. ,   0. ],\n",
       "        [  0. ,   0. ],\n",
       "        [ -0.5,   0. ],\n",
       "        [ -1. ,   0. ],\n",
       "        [  0. ,   1. ],\n",
       "        [  0. ,   1. ],\n",
       "        [  0. ,   2. ],\n",
       "        [  0. ,   1.5],\n",
       "        [  0. ,   2. ],\n",
       "        [  0. ,   3. ],\n",
       "        [  0. ,   1.5],\n",
       "        [  0. ,   2. ],\n",
       "        [  0. ,   2.5],\n",
       "        [  0. ,   1.5],\n",
       "        [  0. ,   1.5],\n",
       "        [  0. ,   1. ],\n",
       "        [  0. ,   1.5],\n",
       "        [  0. ,   0.5],\n",
       "        [ -0.5,   0. ],\n",
       "        [  0. ,   0.5],\n",
       "        [  0. ,   2. ],\n",
       "        [  0. ,   4. ],\n",
       "        [  0. ,   6. ],\n",
       "        [  0. ,   6.5],\n",
       "        [  0. ,   5. ],\n",
       "        [  0. ,   4. ],\n",
       "        [  0. ,   9.5],\n",
       "        [  0. ,  11. ],\n",
       "        [  0. ,   9. ],\n",
       "        [  0. ,   6. ],\n",
       "        [  0. ,   6.5],\n",
       "        [  0. ,   6. ],\n",
       "        [  0. ,   4.5],\n",
       "        [  0. ,   5. ],\n",
       "        [  0. ,   1. ],\n",
       "        [ -6.5,   0. ],\n",
       "        [ -7.5,   0. ],\n",
       "        [ -5.5,   0. ],\n",
       "        [ -3.5,   0. ],\n",
       "        [ -6.5,   0. ],\n",
       "        [-10.5,   0. ],\n",
       "        [ -8.5,   0. ],\n",
       "        [ -8. ,   0. ],\n",
       "        [ -3. ,   0. ],\n",
       "        [ -0.5,   0. ],\n",
       "        [ -1. ,   0. ],\n",
       "        [  0. ,   0.5],\n",
       "        [  0. ,   0. ],\n",
       "        [  0. ,   0. ],\n",
       "        [  0. ,   3. ],\n",
       "        [  0. ,   0. ],\n",
       "        [  0. ,   0.5],\n",
       "        [ -0.5,   0. ],\n",
       "        [ -2. ,   0. ],\n",
       "        [ -1.5,   0. ],\n",
       "        [ -3. ,   0. ],\n",
       "        [ -2.5,   0. ],\n",
       "        [ -1.5,   0. ],\n",
       "        [ -1. ,   0. ],\n",
       "        [  0. ,   1.5],\n",
       "        [  0. ,   0.5],\n",
       "        [  0. ,   0.5],\n",
       "        [  0. ,   1.5],\n",
       "        [  0. ,   1. ],\n",
       "        [ -0.5,   0. ],\n",
       "        [ -1. ,   0. ],\n",
       "        [ -1. ,   0. ],\n",
       "        [ -1. ,   0. ],\n",
       "        [ -2. ,   0. ],\n",
       "        [ -2. ,   0. ],\n",
       "        [ -2. ,   0. ],\n",
       "        [ -2. ,   0. ],\n",
       "        [ -2.5,   0. ],\n",
       "        [ -1.5,   0. ],\n",
       "        [ -1.5,   0. ],\n",
       "        [ -2.5,   0. ],\n",
       "        [ -3. ,   0. ],\n",
       "        [ -3. ,   0. ],\n",
       "        [ -2.5,   0. ],\n",
       "        [ -1.5,   0. ],\n",
       "        [ -1. ,   0. ],\n",
       "        [ -1. ,   0. ],\n",
       "        [ -0.5,   0. ],\n",
       "        [  0. ,   0.5],\n",
       "        [  0. ,   0.5],\n",
       "        [  0. ,   1. ],\n",
       "        [  0. ,   0.5],\n",
       "        [  0. ,   0.5],\n",
       "        [  0. ,   0. ],\n",
       "        [  0. ,   0. ],\n",
       "        [  0. ,   0.5],\n",
       "        [  0. ,   1.5],\n",
       "        [  0. ,   0.5],\n",
       "        [ -0.5,   0. ],\n",
       "        [ -1. ,   0. ],\n",
       "        [  0. ,   0. ],\n",
       "        [  0. ,   0.5],\n",
       "        [ -0.5,   0. ],\n",
       "        [ -0.5,   0. ],\n",
       "        [ -0.5,   0. ],\n",
       "        [ -2. ,   0. ],\n",
       "        [ -4.5,   0. ],\n",
       "        [ -2.5,   0. ],\n",
       "        [ -3.5,   0. ],\n",
       "        [ -3.5,   0. ],\n",
       "        [ -4.5,   0. ],\n",
       "        [ -3. ,   0. ],\n",
       "        [ -1.5,   0. ],\n",
       "        [ -2. ,   0. ],\n",
       "        [ -1.5,   0. ],\n",
       "        [ -1. ,   0. ],\n",
       "        [ -4. ,   0. ],\n",
       "        [ -4. ,   0. ],\n",
       "        [ -2.5,   0. ],\n",
       "        [ -2.5,   0. ],\n",
       "        [ -3. ,   0. ]]),\n",
       " ['rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'rise',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'rise',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'fall',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'rise',\n",
       "  'rise',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall',\n",
       "  'fall'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Y, test_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x7f00ea9f6a10>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "# placeholder\n",
    "input_x = tf.placeholder(tf.float32, [None,D], name=\"input_x\")\n",
    "input_y = tf.placeholder(tf.float32, [None,C], name=\"input_y\")\n",
    "\n",
    "# weights and biases\n",
    "w1 = tf.get_variable(\"W1\", shape=[H, C], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.constant(0.01, shape = [C], name = \"B1\"))\n",
    "\n",
    "input_x1 = tf.reshape(input_x, [-1,n_steps, n_input])\n",
    "input_x2 = tf.transpose(input_x1, [1, 0, 2])\n",
    "input_x3 = tf.reshape(input_x2, [-1, n_input])\n",
    "input_x4 = tf.split(0, n_steps, input_x3)\n",
    "\n",
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(H, forget_bias=1.0)\n",
    "outputs, states = rnn.rnn(lstm_cell, input_x4, dtype=tf.float32)\n",
    "score = tf.matmul(outputs[-1], w1) + b1\n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(score-input_y),reduction_indices=[1]))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loss: 2.00512\n",
      "50\n",
      "loss: 0.482333\n",
      "100\n",
      "loss: 0.360786\n",
      "150\n",
      "loss: 0.322498\n",
      "200\n",
      "loss: 0.299795\n",
      "250\n",
      "loss: 0.281266\n",
      "300\n",
      "loss: 0.265455\n",
      "350\n",
      "loss: 0.25245\n",
      "400\n",
      "loss: 0.240914\n",
      "450\n",
      "loss: 0.230493\n",
      "500\n",
      "loss: 0.219908\n",
      "550\n",
      "loss: 0.206201\n",
      "600\n",
      "loss: 0.188463\n",
      "650\n",
      "loss: 0.169088\n",
      "700\n",
      "loss: 0.14966\n",
      "750\n",
      "loss: 0.130759\n",
      "800\n",
      "loss: 0.113938\n",
      "850\n",
      "loss: 0.0987718\n",
      "900\n",
      "loss: 0.0843451\n",
      "950\n",
      "loss: 0.0702327\n",
      "1000\n",
      "loss: 0.0574554\n",
      "1050\n",
      "loss: 0.0460063\n",
      "1100\n",
      "loss: 0.0363051\n",
      "1150\n",
      "loss: 0.0288095\n",
      "1200\n",
      "loss: 0.0221943\n",
      "1250\n",
      "loss: 0.0168565\n",
      "1300\n",
      "loss: 0.0130563\n",
      "1350\n",
      "loss: 0.0100355\n",
      "1400\n",
      "loss: 0.00800136\n",
      "1450\n",
      "loss: 0.0062785\n",
      "1500\n",
      "loss: 0.00498168\n",
      "1550\n",
      "loss: 0.00772744\n",
      "1600\n",
      "loss: 0.00344167\n",
      "1650\n",
      "loss: 0.00298214\n",
      "1700\n",
      "loss: 0.00256583\n",
      "1750\n",
      "loss: 0.00233399\n",
      "1800\n",
      "loss: 0.00208325\n",
      "1850\n",
      "loss: 0.00192522\n",
      "1900\n",
      "loss: 0.00173077\n",
      "1950\n",
      "loss: 0.00161415\n",
      "2000\n",
      "loss: 0.00151281\n",
      "2050\n",
      "loss: 0.001697\n",
      "2100\n",
      "loss: 0.00136739\n",
      "2150\n",
      "loss: 0.00147712\n",
      "2200\n",
      "loss: 0.0012605\n",
      "2250\n",
      "loss: 0.00122545\n",
      "2300\n",
      "loss: 0.00154678\n",
      "2350\n",
      "loss: 0.00114263\n",
      "2400\n",
      "loss: 0.0011455\n",
      "2450\n",
      "loss: 0.00109136\n",
      "2500\n",
      "loss: 0.00111335\n",
      "2550\n",
      "loss: 0.00102287\n",
      "2600\n",
      "loss: 0.00242115\n",
      "2650\n",
      "loss: 0.000982137\n",
      "2700\n",
      "loss: 0.00095001\n",
      "2750\n",
      "loss: 0.000926322\n",
      "2800\n",
      "loss: 0.00103509\n",
      "2850\n",
      "loss: 0.000884945\n",
      "2900\n",
      "loss: 0.000893363\n",
      "2950\n",
      "loss: 0.00085166\n",
      "3000\n",
      "loss: 0.000818283\n",
      "3050\n",
      "loss: 0.000826534\n",
      "3100\n",
      "loss: 0.000799049\n",
      "3150\n",
      "loss: 0.000778715\n",
      "3200\n",
      "loss: 0.000737959\n",
      "3250\n",
      "loss: 0.000928268\n",
      "3300\n",
      "loss: 0.000696045\n",
      "3350\n",
      "loss: 0.000694398\n",
      "3400\n",
      "loss: 0.000654773\n",
      "3450\n",
      "loss: 0.0006794\n",
      "3500\n",
      "loss: 0.000621331\n",
      "3550\n",
      "loss: 0.000619265\n",
      "3600\n",
      "loss: 0.000620923\n",
      "3650\n",
      "loss: 0.000559406\n",
      "3700\n",
      "loss: 0.0012424\n",
      "3750\n",
      "loss: 0.000526295\n",
      "3800\n",
      "loss: 0.000557449\n",
      "3850\n",
      "loss: 0.000492627\n",
      "3900\n",
      "loss: 0.00048794\n",
      "3950\n",
      "loss: 0.000457087\n",
      "4000\n",
      "loss: 0.00047524\n",
      "4050\n",
      "loss: 0.000702111\n",
      "4100\n",
      "loss: 0.000407805\n",
      "4150\n",
      "loss: 0.000462218\n",
      "4200\n",
      "loss: 0.00114013\n",
      "4250\n",
      "loss: 0.000362015\n",
      "4300\n",
      "loss: 0.00036364\n",
      "4350\n",
      "loss: 0.000333334\n",
      "4400\n",
      "loss: 0.000378185\n",
      "4450\n",
      "loss: 0.000519257\n",
      "4500\n",
      "loss: 0.000307245\n",
      "4550\n",
      "loss: 0.000279834\n",
      "4600\n",
      "loss: 0.000317775\n",
      "4650\n",
      "loss: 0.000256757\n",
      "4700\n",
      "loss: 0.000356555\n",
      "4750\n",
      "loss: 0.000235461\n",
      "4800\n",
      "loss: 0.000279904\n",
      "4850\n",
      "loss: 0.000592462\n",
      "4900\n",
      "loss: 0.000205195\n",
      "4950\n",
      "loss: 0.000583547\n",
      "5000\n",
      "loss: 0.000192561\n",
      "5050\n",
      "loss: 0.000233022\n",
      "5100\n",
      "loss: 0.000179806\n",
      "5150\n",
      "loss: 0.000191851\n",
      "5200\n",
      "loss: 0.000156906\n",
      "5250\n",
      "loss: 0.000531247\n",
      "5300\n",
      "loss: 0.00031563\n",
      "5350\n",
      "loss: 0.000131026\n",
      "5400\n",
      "loss: 0.000891082\n",
      "5450\n",
      "loss: 0.00011306\n",
      "5500\n",
      "loss: 0.000381709\n",
      "5550\n",
      "loss: 0.00115671\n",
      "5600\n",
      "loss: 0.000157732\n",
      "5650\n",
      "loss: 9.25893e-05\n",
      "5700\n",
      "loss: 0.000236767\n",
      "5750\n",
      "loss: 0.000680774\n",
      "5800\n",
      "loss: 9.04986e-05\n",
      "5850\n",
      "loss: 0.000260206\n",
      "5900\n",
      "loss: 6.47979e-05\n",
      "5950\n",
      "loss: 0.000236332\n",
      "6000\n",
      "loss: 0.000336196\n",
      "6050\n",
      "loss: 5.81032e-05\n",
      "6100\n",
      "loss: 5.94324e-05\n",
      "6150\n",
      "loss: 6.55021e-05\n",
      "6200\n",
      "loss: 7.50315e-05\n",
      "6250\n",
      "loss: 5.8644e-05\n",
      "6300\n",
      "loss: 0.000437756\n",
      "6350\n",
      "loss: 4.46697e-05\n",
      "6400\n",
      "loss: 4.227e-05\n",
      "6450\n",
      "loss: 3.22e-05\n",
      "6500\n",
      "loss: 8.1192e-05\n",
      "6550\n",
      "loss: 0.000203192\n",
      "6600\n",
      "loss: 0.000403123\n",
      "6650\n",
      "loss: 0.000537653\n",
      "6700\n",
      "loss: 0.000112616\n",
      "6750\n",
      "loss: 3.85983e-05\n",
      "6800\n",
      "loss: 3.78508e-05\n",
      "6850\n",
      "loss: 0.000300932\n",
      "6900\n",
      "loss: 0.000348985\n",
      "6950\n",
      "loss: 0.000974537\n",
      "7000\n",
      "loss: 0.000115217\n",
      "7050\n",
      "loss: 1.86719e-05\n",
      "7100\n",
      "loss: 2.66677e-05\n",
      "7150\n",
      "loss: 2.63283e-05\n",
      "7200\n",
      "loss: 5.77979e-05\n",
      "7250\n",
      "loss: 0.000501251\n",
      "7300\n",
      "loss: 2.52299e-05\n",
      "7350\n",
      "loss: 7.57744e-05\n",
      "7400\n",
      "loss: 5.40763e-05\n",
      "7450\n",
      "loss: 3.8107e-05\n",
      "7500\n",
      "loss: 0.000373097\n",
      "7550\n",
      "loss: 3.04208e-05\n",
      "7600\n",
      "loss: 0.000548584\n",
      "7650\n",
      "loss: 7.55669e-06\n",
      "7700\n",
      "loss: 0.000138054\n",
      "7750\n",
      "loss: 1.52492e-05\n",
      "7800\n",
      "loss: 4.40093e-05\n",
      "7850\n",
      "loss: 2.16329e-05\n",
      "7900\n",
      "loss: 2.15712e-05\n",
      "7950\n",
      "loss: 5.0916e-06\n",
      "8000\n",
      "loss: 3.55573e-05\n",
      "8050\n",
      "loss: 5.16891e-06\n",
      "8100\n",
      "loss: 5.77503e-05\n",
      "8150\n",
      "loss: 3.09398e-06\n",
      "8200\n",
      "loss: 0.00150849\n",
      "8250\n",
      "loss: 1.01297e-05\n",
      "8300\n",
      "loss: 0.000574325\n",
      "8350\n",
      "loss: 8.9123e-06\n",
      "8400\n",
      "loss: 2.27662e-05\n",
      "8450\n",
      "loss: 2.34751e-06\n",
      "8500\n",
      "loss: 0.00012885\n",
      "8550\n",
      "loss: 3.91867e-06\n",
      "8600\n",
      "loss: 1.78613e-06\n",
      "8650\n",
      "loss: 1.70745e-06\n",
      "8700\n",
      "loss: 1.86408e-05\n",
      "8750\n",
      "loss: 1.92242e-06\n",
      "8800\n",
      "loss: 0.000257383\n",
      "8850\n",
      "loss: 3.62831e-06\n",
      "8900\n",
      "loss: 1.37767e-06\n",
      "8950\n",
      "loss: 0.000212491\n",
      "9000\n",
      "loss: 2.29928e-06\n",
      "9050\n",
      "loss: 9.75099e-05\n",
      "9100\n",
      "loss: 3.14583e-06\n",
      "9150\n",
      "loss: 0.000509202\n",
      "9200\n",
      "loss: 2.10194e-05\n",
      "9250\n",
      "loss: 1.23407e-05\n",
      "9300\n",
      "loss: 0.000617488\n",
      "9350\n",
      "loss: 1.10318e-05\n",
      "9400\n",
      "loss: 3.44426e-06\n",
      "9450\n",
      "loss: 2.37699e-05\n",
      "9500\n",
      "loss: 1.252e-05\n",
      "9550\n",
      "loss: 0.000378933\n",
      "9600\n",
      "loss: 1.49841e-06\n",
      "9650\n",
      "loss: 5.64069e-05\n",
      "9700\n",
      "loss: 0.00020631\n",
      "9750\n",
      "loss: 1.29171e-06\n",
      "9800\n",
      "loss: 0.000116657\n",
      "9850\n",
      "loss: 1.38761e-05\n",
      "9900\n",
      "loss: 4.9788e-05\n",
      "9950\n",
      "loss: 1.71028e-05\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "      \n",
    "    for i in range(10000):\n",
    "        # training\n",
    "        sess.run(optimizer, feed_dict={input_x: train_X, input_y: train_Y})\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "\n",
    "            pred_tag = []\n",
    "            print i\n",
    "            print 'loss:', sess.run(loss, feed_dict={input_x:train_X, input_y: train_Y})\n",
    "\n",
    "            train_prediction = sess.run(score, feed_dict={input_x: train_X})\n",
    "            test_prediction = sess.run(score, feed_dict={input_x: test_X})\n",
    "            \n",
    "            for j in xrange(0, len(test_prediction)):\n",
    "                if test_prediction[j,0]*(-1) - test_prediction[j,1] > 0:\n",
    "                    pred_tag.append('fall')\n",
    "                else:\n",
    "                    pred_tag.append('rise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rise', 'rise', 'rise', 'rise', 'fall', 'rise', 'rise', 'fall', 'rise', 'fall', 'rise', 'fall', 'rise', 'rise', 'rise', 'fall', 'rise', 'rise', 'fall', 'fall', 'fall', 'fall', 'fall', 'rise', 'rise', 'fall', 'fall', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'fall', 'fall', 'rise', 'rise', 'fall', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'rise', 'fall', 'rise', 'rise', 'rise', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'rise', 'rise', 'rise', 'rise', 'rise', 'fall', 'fall', 'rise', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'rise', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'rise', 'rise', 'rise', 'fall', 'fall', 'fall', 'rise', 'rise', 'rise', 'fall', 'fall', 'rise', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'rise', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'rise', 'fall', 'fall', 'fall', 'fall', 'fall']\n",
      "['rise', 'rise', 'rise', 'fall', 'fall', 'rise', 'rise', 'fall', 'fall', 'fall', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'fall', 'fall', 'fall', 'rise', 'fall', 'fall', 'rise', 'fall', 'fall', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'fall', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'rise', 'rise', 'rise', 'rise', 'rise', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'rise', 'fall', 'fall', 'rise', 'rise', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall', 'fall']\n"
     ]
    }
   ],
   "source": [
    "print pred_tag\n",
    "print test_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.804347826087\n",
      "Precision Rate 0.822580645161\n",
      "Recall Rate 0.761194029851\n"
     ]
    }
   ],
   "source": [
    "# confusion matrix\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "for i in xrange (0, len(pred_tag)):\n",
    "    if pred_tag[i] == test_tag[i] and pred_tag[i] == 'rise':\n",
    "        tp = tp + 1\n",
    "    elif test_tag[i] == 'fall' and pred_tag[i] == 'rise':\n",
    "        fp = fp + 1\n",
    "    elif test_tag[i] == 'rise' and pred_tag[i] == 'fall':\n",
    "        fn = fn + 1\n",
    "    else:\n",
    "        tn = tn + 1\n",
    "print 'Accuracy', float(tp + tn) / len(pred_tag)\n",
    "print 'Precision Rate', float(tp) / float(tp + fp)\n",
    "print 'Recall Rate', float(tp) / float(tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "from tensorflow.python.ops import rnn, rnn_cell\n",
    "from yahoo_finance import Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "day_len = 9\n",
    "H = 256 # number of hidden layer neurons\n",
    "D = 9 # input dimensionality\n",
    "C = 1 # ouput classes \n",
    "n_input = 3 # MNIST data input (img shape: 2*2)\n",
    "n_steps = 3 # timesteps\n",
    "n_day = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get 2330 stock data from yahoo-finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1025\n"
     ]
    }
   ],
   "source": [
    "# get stock from yahoo-finance\n",
    "stock = Share('2317.TW')\n",
    "today = datetime.date.today()\n",
    "stock_data = stock.get_historical('2013-01-01', str(today))\n",
    "stock_data.reverse()\n",
    "print len(stock_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### delete the zero-volumn data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data without zero volumn 959\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while( i < len(stock_data)):\n",
    "    if (int(stock_data[i].get('Volume')) <= 0):\n",
    "        stock_data.remove(stock_data[i])\n",
    "        i = -1\n",
    "    i += 1\n",
    "print 'data without zero volumn', len(stock_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_X = np.zeros((len(stock_data)-day_len,day_len), dtype=np.float)\n",
    "data_Y = np.zeros((len(stock_data)-day_len,1), dtype = np.float)\n",
    "\n",
    "for i in xrange(0, len(data_X)):\n",
    "    for j in xrange(0, day_len):\n",
    "        data_X[i,j] = float(stock_data[i+j].get('Close'))\n",
    "        \n",
    "for i in xrange(0, len(data_X)):\n",
    "    tmp = []\n",
    "    for j in xrange(0, day_len):\n",
    "        tmp.append(data_X[i,j])\n",
    "    for j in xrange(0,day_len):\n",
    "        data_X[i,j] = (data_X[i,j]-min(tmp))/(max(tmp)-min(tmp))\n",
    "\n",
    "# rise in n_day or not? 1:rise, 0:otherwise\n",
    "for i in xrange(0, len(data_X)-1-n_day):\n",
    "    for j in xrange(i+day_len+1, i+day_len+1+n_day):\n",
    "        if stock_data[j].get('Close') > stock_data[i+day_len].get('Close'):\n",
    "            data_Y[i] = 1\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len_train = int(len(data_X) * 0.8)\n",
    "len_test = len(data_X) - len_train\n",
    "\n",
    "train_X = data_X[0:len_train]\n",
    "train_Y = data_Y[0:len_train]\n",
    "test_X = data_X[len_train::]\n",
    "test_Y = data_Y[len_train::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x7f4c41883910>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
     ]
    }
   ],
   "source": [
    "# LSTM\n",
    "# placeholder\n",
    "input_x = tf.placeholder(tf.float32, [None,D], name=\"input_x\")\n",
    "input_y = tf.placeholder(tf.float32, [None,C], name=\"input_y\")\n",
    "\n",
    "# weights and biases\n",
    "w1 = tf.get_variable(\"W1\", shape=[H, C], initializer=tf.contrib.layers.xavier_initializer())\n",
    "b1 = tf.Variable(tf.constant(0.01, shape = [C], name = \"B1\"))\n",
    "\n",
    "input_x1 = tf.reshape(input_x, [-1,n_steps, n_input])\n",
    "input_x2 = tf.transpose(input_x1, [1, 0, 2])\n",
    "input_x3 = tf.reshape(input_x2, [-1, n_input])\n",
    "input_x4 = tf.split(0, n_steps, input_x3)\n",
    "\n",
    "lstm_cell = tf.nn.rnn_cell.BasicLSTMCell(H, forget_bias=1.0)\n",
    "outputs, states = rnn.rnn(lstm_cell, input_x4, dtype=tf.float32)\n",
    "score = tf.matmul(outputs[-1], w1) + b1\n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(score-input_y),reduction_indices=[1]))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss) \n",
    "#optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001).minimize(loss) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.initialize_all_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "loss: 0.646797\n",
      "training acc= 0.118421052632\n",
      "testing acc= 0.242105263158\n",
      "50\n",
      "loss: 0.116684\n",
      "training acc= 0.878947368421\n",
      "testing acc= 0.752631578947\n",
      "100\n",
      "loss: 0.11062\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "150\n",
      "loss: 0.107632\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "200\n",
      "loss: 0.105744\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "250\n",
      "loss: 0.10458\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "300\n",
      "loss: 0.103949\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "350\n",
      "loss: 0.103616\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "400\n",
      "loss: 0.103392\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "450\n",
      "loss: 0.10316\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "500\n",
      "loss: 0.102866\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "550\n",
      "loss: 0.102532\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "600\n",
      "loss: 0.102138\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "650\n",
      "loss: 0.101664\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "700\n",
      "loss: 0.101126\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "750\n",
      "loss: 0.100426\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "800\n",
      "loss: 0.0994714\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "850\n",
      "loss: 0.098303\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "900\n",
      "loss: 0.0969118\n",
      "training acc= 0.881578947368\n",
      "testing acc= 0.757894736842\n",
      "950\n",
      "loss: 0.0953457\n",
      "training acc= 0.882894736842\n",
      "testing acc= 0.757894736842\n",
      "1000\n",
      "loss: 0.0937219\n",
      "training acc= 0.884210526316\n",
      "testing acc= 0.757894736842\n",
      "1050\n",
      "loss: 0.0920588\n",
      "training acc= 0.885526315789\n",
      "testing acc= 0.757894736842\n",
      "1100\n",
      "loss: 0.0902931\n",
      "training acc= 0.888157894737\n",
      "testing acc= 0.757894736842\n",
      "1150\n",
      "loss: 0.0880743\n",
      "training acc= 0.889473684211\n",
      "testing acc= 0.757894736842\n",
      "1200\n",
      "loss: 0.0853259\n",
      "training acc= 0.893421052632\n",
      "testing acc= 0.757894736842\n",
      "1250\n",
      "loss: 0.0820008\n",
      "training acc= 0.898684210526\n",
      "testing acc= 0.757894736842\n",
      "1300\n",
      "loss: 0.0781045\n",
      "training acc= 0.902631578947\n",
      "testing acc= 0.757894736842\n",
      "1350\n",
      "loss: 0.0734318\n",
      "training acc= 0.907894736842\n",
      "testing acc= 0.747368421053\n",
      "1400\n",
      "loss: 0.0684229\n",
      "training acc= 0.914473684211\n",
      "testing acc= 0.742105263158\n",
      "1450\n",
      "loss: 0.0627859\n",
      "training acc= 0.917105263158\n",
      "testing acc= 0.747368421053\n",
      "1500\n",
      "loss: 0.0569536\n",
      "training acc= 0.927631578947\n",
      "testing acc= 0.757894736842\n",
      "1550\n",
      "loss: 0.0511608\n",
      "training acc= 0.940789473684\n",
      "testing acc= 0.757894736842\n",
      "1600\n",
      "loss: 0.0461384\n",
      "training acc= 0.951315789474\n",
      "testing acc= 0.742105263158\n",
      "1650\n",
      "loss: 0.0414555\n",
      "training acc= 0.960526315789\n",
      "testing acc= 0.736842105263\n",
      "1700\n",
      "loss: 0.0374304\n",
      "training acc= 0.969736842105\n",
      "testing acc= 0.736842105263\n",
      "1750\n",
      "loss: 0.0344328\n",
      "training acc= 0.968421052632\n",
      "testing acc= 0.736842105263\n",
      "1800\n",
      "loss: 0.0305138\n",
      "training acc= 0.972368421053\n",
      "testing acc= 0.710526315789\n",
      "1850\n",
      "loss: 0.0274796\n",
      "training acc= 0.975\n",
      "testing acc= 0.7\n",
      "1900\n",
      "loss: 0.0249421\n",
      "training acc= 0.977631578947\n",
      "testing acc= 0.7\n",
      "1950\n",
      "loss: 0.0225545\n",
      "training acc= 0.980263157895\n",
      "testing acc= 0.7\n",
      "2000\n",
      "loss: 0.0203983\n",
      "training acc= 0.980263157895\n",
      "testing acc= 0.715789473684\n",
      "2050\n",
      "loss: 0.0187391\n",
      "training acc= 0.981578947368\n",
      "testing acc= 0.710526315789\n",
      "2100\n",
      "loss: 0.0170152\n",
      "training acc= 0.982894736842\n",
      "testing acc= 0.705263157895\n",
      "2150\n",
      "loss: 0.0154396\n",
      "training acc= 0.986842105263\n",
      "testing acc= 0.705263157895\n",
      "2200\n",
      "loss: 0.0141814\n",
      "training acc= 0.988157894737\n",
      "testing acc= 0.705263157895\n",
      "2250\n",
      "loss: 0.0129186\n",
      "training acc= 0.989473684211\n",
      "testing acc= 0.705263157895\n",
      "2300\n",
      "loss: 0.0117257\n",
      "training acc= 0.989473684211\n",
      "testing acc= 0.689473684211\n",
      "2350\n",
      "loss: 0.0110708\n",
      "training acc= 0.993421052632\n",
      "testing acc= 0.684210526316\n",
      "2400\n",
      "loss: 0.00979022\n",
      "training acc= 0.994736842105\n",
      "testing acc= 0.689473684211\n",
      "2450\n",
      "loss: 0.00890613\n",
      "training acc= 0.996052631579\n",
      "testing acc= 0.689473684211\n",
      "2500\n",
      "loss: 0.00806329\n",
      "training acc= 0.996052631579\n",
      "testing acc= 0.689473684211\n",
      "2550\n",
      "loss: 0.00796666\n",
      "training acc= 0.996052631579\n",
      "testing acc= 0.7\n",
      "2600\n",
      "loss: 0.00669246\n",
      "training acc= 0.996052631579\n",
      "testing acc= 0.689473684211\n",
      "2650\n",
      "loss: 0.0060549\n",
      "training acc= 0.997368421053\n",
      "testing acc= 0.689473684211\n",
      "2700\n",
      "loss: 0.00545689\n",
      "training acc= 0.998684210526\n",
      "testing acc= 0.694736842105\n",
      "2750\n",
      "loss: 0.00590716\n",
      "training acc= 1.0\n",
      "testing acc= 0.710526315789\n",
      "2800\n",
      "loss: 0.00444669\n",
      "training acc= 1.0\n",
      "testing acc= 0.7\n",
      "2850\n",
      "loss: 0.00400062\n",
      "training acc= 1.0\n",
      "testing acc= 0.705263157895\n",
      "2900\n",
      "loss: 0.00635108\n",
      "training acc= 0.998684210526\n",
      "testing acc= 0.715789473684\n",
      "2950\n",
      "loss: 0.00326466\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n",
      "3000\n",
      "loss: 0.00293598\n",
      "training acc= 1.0\n",
      "testing acc= 0.7\n",
      "3050\n",
      "loss: 0.00263291\n",
      "training acc= 1.0\n",
      "testing acc= 0.705263157895\n",
      "3100\n",
      "loss: 0.00235096\n",
      "training acc= 1.0\n",
      "testing acc= 0.705263157895\n",
      "3150\n",
      "loss: 0.00235993\n",
      "training acc= 1.0\n",
      "testing acc= 0.710526315789\n",
      "3200\n",
      "loss: 0.00191318\n",
      "training acc= 1.0\n",
      "testing acc= 0.710526315789\n",
      "3250\n",
      "loss: 0.00170977\n",
      "training acc= 1.0\n",
      "testing acc= 0.710526315789\n",
      "3300\n",
      "loss: 0.00152874\n",
      "training acc= 1.0\n",
      "testing acc= 0.710526315789\n",
      "3350\n",
      "loss: 0.00138648\n",
      "training acc= 1.0\n",
      "testing acc= 0.710526315789\n",
      "3400\n",
      "loss: 0.00124037\n",
      "training acc= 1.0\n",
      "testing acc= 0.710526315789\n",
      "3450\n",
      "loss: 0.00110941\n",
      "training acc= 1.0\n",
      "testing acc= 0.705263157895\n",
      "3500\n",
      "loss: 0.000989941\n",
      "training acc= 1.0\n",
      "testing acc= 0.705263157895\n",
      "3550\n",
      "loss: 0.000880768\n",
      "training acc= 1.0\n",
      "testing acc= 0.7\n",
      "3600\n",
      "loss: 0.000808471\n",
      "training acc= 1.0\n",
      "testing acc= 0.7\n",
      "3650\n",
      "loss: 0.00071962\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n",
      "3700\n",
      "loss: 0.000644317\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n",
      "3750\n",
      "loss: 0.00057596\n",
      "training acc= 1.0\n",
      "testing acc= 0.689473684211\n",
      "3800\n",
      "loss: 0.000513812\n",
      "training acc= 1.0\n",
      "testing acc= 0.684210526316\n",
      "3850\n",
      "loss: 0.0010209\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n",
      "3900\n",
      "loss: 0.000414849\n",
      "training acc= 1.0\n",
      "testing acc= 0.684210526316\n",
      "3950\n",
      "loss: 0.000371642\n",
      "training acc= 1.0\n",
      "testing acc= 0.678947368421\n",
      "4000\n",
      "loss: 0.000963995\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n",
      "4050\n",
      "loss: 0.000319155\n",
      "training acc= 1.0\n",
      "testing acc= 0.678947368421\n",
      "4100\n",
      "loss: 0.000276312\n",
      "training acc= 1.0\n",
      "testing acc= 0.678947368421\n",
      "4150\n",
      "loss: 0.000248686\n",
      "training acc= 1.0\n",
      "testing acc= 0.689473684211\n",
      "4200\n",
      "loss: 0.000223589\n",
      "training acc= 1.0\n",
      "testing acc= 0.689473684211\n",
      "4250\n",
      "loss: 0.000200787\n",
      "training acc= 1.0\n",
      "testing acc= 0.689473684211\n",
      "4300\n",
      "loss: 0.00356965\n",
      "training acc= 1.0\n",
      "testing acc= 0.689473684211\n",
      "4350\n",
      "loss: 0.000184171\n",
      "training acc= 1.0\n",
      "testing acc= 0.689473684211\n",
      "4400\n",
      "loss: 0.000150924\n",
      "training acc= 1.0\n",
      "testing acc= 0.689473684211\n",
      "4450\n",
      "loss: 0.000192944\n",
      "training acc= 1.0\n",
      "testing acc= 0.689473684211\n",
      "4500\n",
      "loss: 0.000147957\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n",
      "4550\n",
      "loss: 0.000115064\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n",
      "4600\n",
      "loss: 0.000104216\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n",
      "4650\n",
      "loss: 9.44408e-05\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n",
      "4700\n",
      "loss: 0.000435945\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n",
      "4750\n",
      "loss: 8.39587e-05\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n",
      "4800\n",
      "loss: 7.38011e-05\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n",
      "4850\n",
      "loss: 6.70263e-05\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n",
      "4900\n",
      "loss: 6.0851e-05\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n",
      "4950\n",
      "loss: 0.000169284\n",
      "training acc= 1.0\n",
      "testing acc= 0.694736842105\n"
     ]
    }
   ],
   "source": [
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    for i in range(5000):\n",
    "        \n",
    "        # training\n",
    "        sess.run(optimizer, feed_dict={input_x: train_X, input_y: train_Y})\n",
    "        \n",
    "        if i % 50 == 0:\n",
    "            \n",
    "            print i\n",
    "            print 'loss:', sess.run(loss, feed_dict={input_x:train_X, input_y: train_Y})\n",
    "\n",
    "            train_prediction = sess.run(score, feed_dict={input_x: train_X})\n",
    "            for i in xrange(0, len(train_prediction)):\n",
    "                if train_prediction[i] >= 0.5:\n",
    "                    train_prediction[i] = 1\n",
    "                else:\n",
    "                    train_prediction[i] = 0\n",
    "                \n",
    "            test_prediction = sess.run(score, feed_dict={input_x: test_X})\n",
    "            for i in xrange(0, len(test_prediction)):\n",
    "                if test_prediction[i] >= 0.5:\n",
    "                    test_prediction[i] = 1\n",
    "                else:\n",
    "                    test_prediction[i] = 0\n",
    "                    \n",
    "            train_acc = 0\n",
    "            test_acc = 0\n",
    "\n",
    "            for i in xrange(0, len(train_prediction)):\n",
    "                #train_prediction[i] = round(train_prediction[i])\n",
    "                if train_prediction[i] == train_Y[i]:\n",
    "                    train_acc = train_acc + 1\n",
    "            train_acc = float(train_acc) / float(len(train_prediction))\n",
    "        \n",
    "            for i in xrange(0, len(test_prediction)):\n",
    "                #test_prediction[i] = round(test_prediction[i])\n",
    "                if test_prediction[i] == test_Y[i]:\n",
    "                    test_acc = test_acc + 1\n",
    "            test_acc = float(test_acc) / float(len(test_prediction))\n",
    "            \n",
    "            print 'training acc=', train_acc\n",
    "            print 'testing acc=', test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.782894736842\n"
     ]
    }
   ],
   "source": [
    "TP = 0\n",
    "FP = 0\n",
    "for i in xrange(0,len(test_Y)):\n",
    "    if test_Y[i]==1 and test_Y[i]==test_prediction[i]:\n",
    "        TP = TP + 1\n",
    "    elif test_Y[i]==0 and test_prediction[i]==1:\n",
    "        FP = FP+1\n",
    "TP = float(TP) / float((TP+FP))\n",
    "print 'precision:',TP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 0.],\n",
       "       [ 1.],\n",
       "       [ 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
